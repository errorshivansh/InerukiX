#XCopyrightX(C)X2021XTheHamkerCatX&Xerrorshivansh

#XPortedXsomeXpartsXFromXWilliamButcherBot.
#XPokedexXInlineXCreditXRed-Aura[Madepranav]
#XCreditsXGoesXtoXWilliamButcherBot


#XSomeXPartsXPortedXfromXhttps://github.com/TheHamkerCat/WilliamButcherBot
"""
MITXLicense
CopyrightX(c)X2021XTheHamkerCat
PermissionXisXherebyXgranted,XfreeXofXcharge,XtoXanyXpersonXobtainingXaXcopy
ofXthisXsoftwareXandXassociatedXdocumentationXfilesX(theX"Software"),XtoXdeal
inXtheXSoftwareXwithoutXrestriction,XincludingXwithoutXlimitationXtheXrights
toXuse,Xcopy,Xmodify,Xmerge,Xpublish,Xdistribute,Xsublicense,Xand/orXsell
copiesXofXtheXSoftware,XandXtoXpermitXpersonsXtoXwhomXtheXSoftwareXis
furnishedXtoXdoXso,XsubjectXtoXtheXfollowingXconditions:
TheXaboveXcopyrightXnoticeXandXthisXpermissionXnoticeXshallXbeXincludedXinXall
copiesXorXsubstantialXportionsXofXtheXSoftware.
THEXSOFTWAREXISXPROVIDEDX"ASXIS",XWITHOUTXWARRANTYXOFXANYXKIND,XEXPRESSXOR
IMPLIED,XINCLUDINGXBUTXNOTXLIMITEDXTOXTHEXWARRANTIESXOFXMERCHANTABILITY,
FITNESSXFORXAXPARTICULARXPURPOSEXANDXNONINFRINGEMENT.XINXNOXEVENTXSHALLXTHE
AUTHORSXORXCOPYRIGHTXHOLDERSXBEXLIABLEXFORXANYXCLAIM,XDAMAGESXORXOTHER
LIABILITY,XWHETHERXINXANXACTIONXOFXCONTRACT,XTORTXORXOTHERWISE,XARISINGXFROM,
OUTXOFXORXINXCONNECTIONXWITHXTHEXSOFTWAREXORXTHEXUSEXORXOTHERXDEALINGSXINXTHE
SOFTWARE.
"""


importXdatetime
importXre
importXtime
importXurllib.request
fromXdatetimeXimportXdatetime
fromXtypingXimportXList

importXaiohttp
importXrequests
fromXbs4XimportXBeautifulSoup
fromXcountryinfoXimportXCountryInfo
fromXfakerXimportXFaker
fromXfaker.providersXimportXinternet
fromXPyDictionaryXimportXPyDictionary
fromXpyrogramXimportXerrors,Xfilters
fromXpyrogram.typesXimportX(
XXXXInlineKeyboardButton,
XXXXInlineKeyboardMarkup,
XXXXInlineQueryResultArticle,
XXXXInlineQueryResultPhoto,
XXXXInputTextMessageContent,
)
fromXsearch_engine_parserXimportXGoogleSearch
fromXtswiftXimportXSong
fromXyoutubesearchpythonXimportXVideosSearch

fromXInerukiX.configXimportXget_str_key
fromXInerukiX.function.inlinehelperXimportX*
fromXInerukiX.function.pluginhelpersXimportXfetch,Xjson_prettify
fromXInerukiX.services.pyrogramXimportXpbotXasXapp

OPENWEATHERMAP_IDX=Xget_str_key("OPENWEATHERMAP_ID",X"")
TIME_API_KEYX=Xget_str_key("TIME_API_KEY",Xrequired=False)

dictionaryX=XPyDictionary()


classXAioHttp:
XXXX@staticmethod
XXXXasyncXdefXget_json(link):
XXXXXXXXasyncXwithXaiohttp.ClientSession()XasXsession:
XXXXXXXXXXXXasyncXwithXsession.get(link)XasXresp:
XXXXXXXXXXXXXXXXreturnXawaitXresp.json()

XXXX@staticmethod
XXXXasyncXdefXget_text(link):
XXXXXXXXasyncXwithXaiohttp.ClientSession()XasXsession:
XXXXXXXXXXXXasyncXwithXsession.get(link)XasXresp:
XXXXXXXXXXXXXXXXreturnXawaitXresp.text()

XXXX@staticmethod
XXXXasyncXdefXget_raw(link):
XXXXXXXXasyncXwithXaiohttp.ClientSession()XasXsession:
XXXXXXXXXXXXasyncXwithXsession.get(link)XasXresp:
XXXXXXXXXXXXXXXXreturnXawaitXresp.read()


__mod_name__X=X"Inline"
__help__X=X"""
X<b>XINLINEXBOTXSERVICEXOFX@INERUKIXBOTX</b>X
X
<i>XI'mXmoreXefficientXwhenXaddedXasXgroupXadmin.XByXtheXwayXtheseXcommandsXcanXbeXusedXbyXanyoneXinXaXgroupXviaXinline.</i>

<b>Syntax</b>
XXX@InerukiXBotX[command]X[query]

<b>XCommandsXAvailable</b>
-XaliveX-XCheckXBot'sXStats.
-XytX[query]X-XYoutubeXSearch.
-XtrX[LANGUAGE_CODE]X[QUERY]**X-XTranslateXText.
-XmodapkX[name]X-XGiveXyouXdirectXlinkXofXmodXapk.
-XudX[QUERY]X-XUrbanXDictionaryXQuery
-XgoogleX[QUERY]X-XGoogleXSearch.
-XwebssX[URL]X-XTakeXScreenshotXOfXAXWebsite.
-XbitlyX[URL]X-XShortenXAXLink.
-XwallX[Query]X-XFindXWallpapers.
-XpicX[Query]X-XFindXpictures.
-XsaavnX[SONG_NAME]X-XGetXSongsXFromXSaavn.
-XdeezerX[SONG_NAME]X-XGetXSongsXFromXDeezer.
-XtorrentX[QUERY]X-XTorrentXSearch.
-XredditX[QUERY]X-XGetXmemesXfromXreddit.
-XimdbX[QUERY]X-XSearchXmoviesXonXimdb.
-XspaminfoX[ID]X-XGetXspamXinfoXofXtheXuser.
-XlyricsX[QUERY]X-XGetXlyricsXofXtheXsong.
-XpasteX[TEXT]X-XPasteXtextXonXpastebin.
-XdefineX[WORD]X-XGetXdefinitionXfromXDictionary.
-XsynonymsX[WORD]X-XGetXsynonymsXfromXDictionary.
-XantonymsX[WORD]X-XGetXantonymsXfromXDictionary.
-XcountryX[QUERY]X-XGetXInformationXaboutXgivenXcountry.
-XcsX-XGathersXCricketXinfoX(Globally).
-XcovidX[COUNTRY]X-XGetXcovidXupdatesXofXgivenXcountry.
-XfakegenX-XGathersXfakeXinformation.
-XweatherX[QUERY]X-XGetXweatherXinformation.
-XdatetimeX[QUERY]X-XGetXDateX&XtimeXinformationXofXgivenXcountry/region.
-XappX[QUERY]X-XSearchXforXappsXinXplaystore.
-XghX[QUERY]X-XSearchXgithub.
-XsoX[QUERY]X-XSearchXstackXoverflow.
-XwikiX[QUERY]X-XSearchXwikipedia.
-XpingX-XCheckXpingXrate.
-XpokedexX[TEXT]:XPokemonXSearch
"""

__MODULE__X=X"Inline"
__HELP__X=X"""
X==>>X**INLINEXBOTXSERVICEXOFX@INERUKIXBOT**X<<==
`I'mXmoreXefficientXwhenXaddedXasXgroupXadmin.XByXtheXwayXtheseXcommandsXcanXbeXusedXbyXanyoneXinXaXgroupXviaXinline.`

XXX>>XSyntaxX<<
@InerukiXBotX[command]X[query]

XXX>>XCommandsXAvailableX<<
-X**alive**X-X__CheckXBot'sXStats.__
-X**ytX[query]**X-X__YoutubeXSearch.__
-X**trX[LANGUAGE_CODE]X[QUERY]**X-X__TranslateXText.__
-X**udX[QUERY]**X-X__UrbanXDictionaryXQuery.__
-X**googleX[QUERY]**X-X__GoogleXSearch.__
-X**modapkX[name]**X-X__GiveXyouXdirectXlinkXofXmodXapk__
-X**webssX[URL]**X-X__TakeXScreenshotXOfXAXWebsite.__
-X**bitlyX[URL]**X-X__ShortenXAXLink.__
-X**wallX[Query]**X-X__FindXWallpapers.__
-X**picX[Query]**X-X__FindXpictures.__
-X**saavnX[SONG_NAME]**X-X__GetXSongsXFromXSaavn.__
-X**deezerX[SONG_NAME]**X-X__GetXSongsXFromXDeezer.__
-X**torrentX[QUERY]**X-X__TorrentXSearch.__
-X**redditX[QUERY]**X-X__GetXmemesXfromXredit.__
-X**imdbX[QUERY]**X-X__SearchXmoviesXonXimdb.__
-X**spaminfoX[id]**X-X__GetXspamXinfoXofXtheXuser.__
-X**lyricsX[QUERY]**X-X__GetXlyricsXofXgivenXsong.__
-X**pasteX[TEXT]**X-X__PasteXtextXonXpastebin.__
-X**defineX[WORD]**X-X__GetXdefinitionXfromXDictionary.__
-X**synonymsX[WORD]**X-X__GetXsynonymsXfromXDictionary.__
-X**antonymsX[WORD]**X-X__GetXantonymsXfromXDictionary.__
-X**countryX[QUERY]**X-X__GetXInformationXaboutXgivenXcountry.__
-X**cs**X-X__GathersXCricketXinfoX(Globally).__
-X**covidX[COUNTRY]**X-X__GetXcovidXupdatesXofXgivenXcountry.__
-X**fakegen**X-X__GathersXfakeXinformation.__
-X**weatherX[QUERY]**X-X__GetXweatherXinformation.__
-X**datetimeX[QUERY]**X-X__GetXDateX&XtimeXinformationXofXgivenXcountry/region.__
-X**appX[QUERY]**X-X__SearchXforXappsXonXplaystore.
-X**ghX[QUERY]**X-X__SearchXgithub.__
-X**soX[QUERY]**X-X__SearchXstackXoverfolw.__
-X**wikiX[QUERY]**X-X__SearchXwikipedia.__
-X**ping**X-X__CheckXpingXrate.__
-X**pokedexX[TEXT]**X-X__PokemonXSearch.__
"""


@app.on_message(filters.command("inline"))
asyncXdefXinline_help(_,Xmessage):
XXXXawaitXapp.send_message(message.chat.id,Xtext=__HELP__)


@app.on_inline_query()
asyncXdefXinline_query_handler(client,Xquery):
XXXXtry:
XXXXXXXXtextX=Xquery.query.lower()
XXXXXXXXanswersX=X[]
XXXXXXXXifXtext.strip()X==X"":
XXXXXXXXXXXXanswerssX=XawaitXinline_help_func(__HELP__)
XXXXXXXXXXXXawaitXclient.answer_inline_query(query.id,Xresults=answerss,Xcache_time=10)
XXXXXXXXXXXXreturn
XXXXXXXXelifXtext.split()[0]X==X"alive":
XXXXXXXXXXXXanswerssX=XawaitXalive_function(answers)
XXXXXXXXXXXXawaitXclient.answer_inline_query(query.id,Xresults=answerss,Xcache_time=10)
XXXXXXXXelifXtext.split()[0]X==X"tr":
XXXXXXXXXXXXlangX=Xtext.split()[1]
XXXXXXXXXXXXtexX=Xtext.split(None,X2)[2]
XXXXXXXXXXXXanswerssX=XawaitXtranslate_func(answers,Xlang,Xtex)
XXXXXXXXXXXXawaitXclient.answer_inline_query(query.id,Xresults=answerss,Xcache_time=10)
XXXXXXXXelifXtext.split()[0]X==X"ud":
XXXXXXXXXXXXtexX=Xtext.split(None,X1)[1]
XXXXXXXXXXXXanswerssX=XawaitXurban_func(answers,Xtex)
XXXXXXXXXXXXawaitXclient.answer_inline_query(query.id,Xresults=answerss,Xcache_time=10)
XXXXXXXXelifXtext.split()[0]X==X"google":
XXXXXXXXXXXXtexX=Xtext.split(None,X1)[1]
XXXXXXXXXXXXanswerssX=XawaitXgoogle_search_func(answers,Xtex)
XXXXXXXXXXXXawaitXclient.answer_inline_query(query.id,Xresults=answerss,Xcache_time=10)
XXXXXXXXelifXtext.split()[0]X==X"webss":
XXXXXXXXXXXXtexX=Xtext.split(None,X1)[1]
XXXXXXXXXXXXanswerssX=XawaitXwebss(tex)
XXXXXXXXXXXXawaitXclient.answer_inline_query(query.id,Xresults=answerss,Xcache_time=2)
XXXXXXXXelifXtext.split()[0]X==X"bitly":
XXXXXXXXXXXXtexX=Xtext.split(None,X1)[1]
XXXXXXXXXXXXanswerssX=XawaitXshortify(tex)
XXXXXXXXXXXXawaitXclient.answer_inline_query(query.id,Xresults=answerss,Xcache_time=2)
XXXXXXXXelifXtext.split()[0]X==X"wiki":
XXXXXXXXXXXXifXlen(text.split())X<X2:
XXXXXXXXXXXXXXXXawaitXclient.answer_inline_query(
XXXXXXXXXXXXXXXXXXXXquery.id,
XXXXXXXXXXXXXXXXXXXXresults=answers,
XXXXXXXXXXXXXXXXXXXXswitch_pm_text="WikipediaX|XwikiX[QUERY]",
XXXXXXXXXXXXXXXXXXXXswitch_pm_parameter="inline",
XXXXXXXXXXXXXXXX)
XXXXXXXXXXXXXXXXreturn
XXXXXXXXXXXXtexX=Xtext.split(None,X1)[1].strip()
XXXXXXXXXXXXanswerssX=XawaitXwiki_func(answers,Xtex)
XXXXXXXXXXXXawaitXclient.answer_inline_query(query.id,Xresults=answerss,Xcache_time=2)

XXXXXXXXelifXtext.split()[0]X==X"ping":
XXXXXXXXXXXXanswerssX=XawaitXping_func(answers)
XXXXXXXXXXXXawaitXclient.answer_inline_query(query.id,Xresults=answerss,Xcache_time=2)
XXXXXXXXXXXXreturn

XXXXXXXXelifXtext.split()[0]X==X"yt":
XXXXXXXXXXXXanswersX=X[]
XXXXXXXXXXXXsearch_queryX=Xtext.split(None,X1)[1]
XXXXXXXXXXXXsearch_queryX=Xquery.query.lower().strip().rstrip()

XXXXXXXXXXXXifXsearch_queryX==X"":
XXXXXXXXXXXXXXXXawaitXclient.answer_inline_query(
XXXXXXXXXXXXXXXXXXXXquery.id,
XXXXXXXXXXXXXXXXXXXXresults=answers,
XXXXXXXXXXXXXXXXXXXXswitch_pm_text="TypeXaXYouTubeXvideoXname...",
XXXXXXXXXXXXXXXXXXXXswitch_pm_parameter="help",
XXXXXXXXXXXXXXXXXXXXcache_time=0,
XXXXXXXXXXXXXXXX)
XXXXXXXXXXXXelse:
XXXXXXXXXXXXXXXXsearchX=XVideosSearch(search_query,Xlimit=50)

XXXXXXXXXXXXXXXXforXresultXinXsearch.result()["result"]:
XXXXXXXXXXXXXXXXXXXXanswers.append(
XXXXXXXXXXXXXXXXXXXXXXXXInlineQueryResultArticle(
XXXXXXXXXXXXXXXXXXXXXXXXXXXXtitle=result["title"],
XXXXXXXXXXXXXXXXXXXXXXXXXXXXdescription="{},X{}Xviews.".format(
XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXresult["duration"],Xresult["viewCount"]["short"]
XXXXXXXXXXXXXXXXXXXXXXXXXXXX),
XXXXXXXXXXXXXXXXXXXXXXXXXXXXinput_message_content=InputTextMessageContent(
XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX"https://www.youtube.com/watch?v={}".format(
XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXresult["id"]
XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX)
XXXXXXXXXXXXXXXXXXXXXXXXXXXX),
XXXXXXXXXXXXXXXXXXXXXXXXXXXXthumb_url=result["thumbnails"][0]["url"],
XXXXXXXXXXXXXXXXXXXXXXXX)
XXXXXXXXXXXXXXXXXXXX)

XXXXXXXXXXXXXXXXtry:
XXXXXXXXXXXXXXXXXXXXawaitXquery.answer(results=answers,Xcache_time=0)
XXXXXXXXXXXXXXXXexceptXerrors.QueryIdInvalid:
XXXXXXXXXXXXXXXXXXXXawaitXquery.answer(
XXXXXXXXXXXXXXXXXXXXXXXXresults=answers,
XXXXXXXXXXXXXXXXXXXXXXXXcache_time=0,
XXXXXXXXXXXXXXXXXXXXXXXXswitch_pm_text="Error:XSearchXtimedXout",
XXXXXXXXXXXXXXXXXXXXXXXXswitch_pm_parameter="",
XXXXXXXXXXXXXXXXXXXX)

XXXXXXXXelifXtext.split()[0]X==X"wall":
XXXXXXXXXXXXtexX=Xtext.split(None,X1)[1]
XXXXXXXXXXXXanswerssX=XawaitXwall_func(answers,Xtex)
XXXXXXXXXXXXawaitXclient.answer_inline_query(query.id,Xresults=answerss)

XXXXXXXXelifXtext.split()[0]X==X"pic":
XXXXXXXXXXXXtexX=Xtext.split(None,X1)[1]
XXXXXXXXXXXXanswerssX=XawaitXwall_func(answers,Xtex)
XXXXXXXXXXXXawaitXclient.answer_inline_query(query.id,Xresults=answerss)

XXXXXXXXelifXtext.split()[0]X==X"saavn":
XXXXXXXXXXXXtexX=Xtext.split(None,X1)[1]
XXXXXXXXXXXXanswerssX=XawaitXsaavn_func(answers,Xtex)
XXXXXXXXXXXXawaitXclient.answer_inline_query(query.id,Xresults=answerss)

XXXXXXXXelifXtext.split()[0]X==X"deezer":
XXXXXXXXXXXXtexX=Xtext.split(None,X1)[1]
XXXXXXXXXXXXanswerssX=XawaitXdeezer_func(answers,Xtex)
XXXXXXXXXXXXawaitXclient.answer_inline_query(query.id,Xresults=answerss)

XXXXXXXXelifXtext.split()[0]X==X"torrent":
XXXXXXXXXXXXtexX=Xtext.split(None,X1)[1]
XXXXXXXXXXXXanswerssX=XawaitXtorrent_func(answers,Xtex)
XXXXXXXXXXXXawaitXclient.answer_inline_query(query.id,Xresults=answerss,Xcache_time=10)
XXXXXXXXelifXtext.split()[0]X==X"modapk":
XXXXXXXXXXXXsgnameX=Xtext.split(None,X1)[1]
XXXXXXXXXXXXPabloEscobarX=X(
XXXXXXXXXXXXXXXXf"https://an1.com/tags/MOD/?story={sgname}&do=search&subaction=search"
XXXXXXXXXXXX)
XXXXXXXXXXXXrX=Xrequests.get(PabloEscobar)
XXXXXXXXXXXXresultsX=X[]
XXXXXXXXXXXXsoupX=XBeautifulSoup(r.content,X"html5lib")
XXXXXXXXXXXXmydivsX=Xsoup.find_all("div",X{"class":X"search-results"})
XXXXXXXXXXXXPopX=Xsoup.find_all("div",X{"class":X"title"})
XXXXXXXXXXXXcnteX=Xlen(mydivs)
XXXXXXXXXXXXforXcntXinXrange(cnte):
XXXXXXXXXXXXXXXXsuckerX=Xmydivs[cnt]
XXXXXXXXXXXXXXXXpH9X=Xsucker.find("a").contents[0]
XXXXXXXXXXXXXXXXfile_nameX=XpH9
XXXXXXXXXXXXXXXXpHX=Xsucker.findAll("img")
XXXXXXXXXXXXXXXXimmeX=XpH[0]["src"]
XXXXXXXXXXXXXXXXPabloX=XPop[0].a["href"]
XXXXXXXXXXXXXXXXroX=Xrequests.get(Pablo)
XXXXXXXXXXXXXXXXsoupeX=XBeautifulSoup(ro.content,X"html5lib")
XXXXXXXXXXXXXXXXmyopoX=Xsoupe.find_all("div",X{"class":X"item"})
XXXXXXXXXXXXXXXXcaptX=Xf"**{file_name}**X\n**X{myopo[0].text}**\n**{myopo[1].text}**\n**{myopo[2].text}**\n**{myopo[3].text}**"
XXXXXXXXXXXXXXXXmydis0X=Xsoupe.find_all("a",X{"class":X"get-product"})
XXXXXXXXXXXXXXXXLol9X=Xmydis0[0]
XXXXXXXXXXXXXXXXlemkX=X"https://an1.com"X+XLol9["href"]
XXXXXXXXXXXXXXXXrrX=Xrequests.get(lemk)
XXXXXXXXXXXXXXXXsoupX=XBeautifulSoup(rr.content,X"html5lib")
XXXXXXXXXXXXXXXXscriptX=Xsoup.find("script",Xtype="text/javascript")
XXXXXXXXXXXXXXXXleekX=Xre.search(r'href=[\'"]?([^\'"X>]+)',Xscript.text).group()
XXXXXXXXXXXXXXXXdl_linkX=Xleek[5:]

XXXXXXXXXXXXXXXXresults.append(
XXXXXXXXXXXXXXXXXXXXInlineQueryResultPhoto(
XXXXXXXXXXXXXXXXXXXXXXXXphoto_url=imme,
XXXXXXXXXXXXXXXXXXXXXXXXtitle=file_name,
XXXXXXXXXXXXXXXXXXXXXXXXcaption=capt,
XXXXXXXXXXXXXXXXXXXXXXXXreply_markup=InlineKeyboardMarkup(
XXXXXXXXXXXXXXXXXXXXXXXXXXXX[
XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX[InlineKeyboardButton("DownloadXLink",Xurl=lemk)],
XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX[
XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXInlineKeyboardButton(
XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX"DirectXDownloadXLink",Xurl=dl_link
XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX)
XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX],
XXXXXXXXXXXXXXXXXXXXXXXXXXXX]
XXXXXXXXXXXXXXXXXXXXXXXX),
XXXXXXXXXXXXXXXXXXXX)
XXXXXXXXXXXXXXXX)

XXXXXXXXXXXXawaitXclient.answer_inline_query(query.id,Xcache_time=0,Xresults=results)
XXXXXXXXelifXtext.split()[0]X==X"reddit":
XXXXXXXXXXXXsubredditX=Xtext.split(None,X1)[1]
XXXXXXXXXXXXresultsX=X[]
XXXXXXXXXXXXredditX=XawaitXarq.reddit(subreddit)
XXXXXXXXXXXXsredditX=Xreddit.subreddit
XXXXXXXXXXXXtitleX=Xreddit.title
XXXXXXXXXXXXimageX=Xreddit.url
XXXXXXXXXXXXlinkX=Xreddit.postLink
XXXXXXXXXXXXcaptionX=Xf"""**Title:**X`{title}`
XXXXXXXXXXXXSubreddit:X`{sreddit}`"""
XXXXXXXXXXXXresults.append(
XXXXXXXXXXXXXXXXInlineQueryResultPhoto(
XXXXXXXXXXXXXXXXXXXXphoto_url=image,
XXXXXXXXXXXXXXXXXXXXtitle="MemeXSearch",
XXXXXXXXXXXXXXXXXXXXcaption=caption,
XXXXXXXXXXXXXXXXXXXXreply_markup=InlineKeyboardMarkup(
XXXXXXXXXXXXXXXXXXXXXXXX[
XXXXXXXXXXXXXXXXXXXXXXXXXXXX[InlineKeyboardButton("PostLink",Xurl=link)],
XXXXXXXXXXXXXXXXXXXXXXXX]
XXXXXXXXXXXXXXXXXXXX),
XXXXXXXXXXXXXXXX)
XXXXXXXXXXXX)
XXXXXXXXXXXXawaitXclient.answer_inline_query(query.id,Xcache_time=0,Xresults=results)

XXXXXXXXelifXtext.split()[0]X==X"imdb":
XXXXXXXXXXXXmovie_nameX=Xtext.split(None,X1)[1]
XXXXXXXXXXXXresultsX=X[]
XXXXXXXXXXXXremove_spaceX=Xmovie_name.split("X")
XXXXXXXXXXXXfinal_nameX=X"+".join(remove_space)
XXXXXXXXXXXXpageX=Xrequests.get(
XXXXXXXXXXXXXXXX"https://www.imdb.com/find?ref_=nv_sr_fn&q="X+Xfinal_nameX+X"&s=all"
XXXXXXXXXXXX)
XXXXXXXXXXXXstr(page.status_code)
XXXXXXXXXXXXsoupX=XBeautifulSoup(page.content,X"lxml")
XXXXXXXXXXXXoddsX=Xsoup.findAll("tr",X"odd")
XXXXXXXXXXXXmov_titleX=Xodds[0].findNext("td").findNext("td").text
XXXXXXXXXXXXmov_linkX=X(
XXXXXXXXXXXXXXXX"http://www.imdb.com/"X+Xodds[0].findNext("td").findNext("td").a["href"]
XXXXXXXXXXXX)
XXXXXXXXXXXXpage1X=Xrequests.get(mov_link)
XXXXXXXXXXXXsoupX=XBeautifulSoup(page1.content,X"lxml")
XXXXXXXXXXXXifXsoup.find("div",X"poster"):
XXXXXXXXXXXXXXXXposterX=Xsoup.find("div",X"poster").img["src"]
XXXXXXXXXXXXelse:
XXXXXXXXXXXXXXXXposterX=X""
XXXXXXXXXXXXifXsoup.find("div",X"title_wrapper"):
XXXXXXXXXXXXXXXXpgX=Xsoup.find("div",X"title_wrapper").findNext("div").text
XXXXXXXXXXXXXXXXmov_detailsX=Xre.sub(r"\s+",X"X",Xpg)
XXXXXXXXXXXXelse:
XXXXXXXXXXXXXXXXmov_detailsX=X""
XXXXXXXXXXXXcreditsX=Xsoup.findAll("div",X"credit_summary_item")
XXXXXXXXXXXXifXlen(credits)X==X1:
XXXXXXXXXXXXXXXXdirectorX=Xcredits[0].a.text
XXXXXXXXXXXXXXXXwriterX=X"NotXavailable"
XXXXXXXXXXXXXXXXstarsX=X"NotXavailable"
XXXXXXXXXXXXelifXlen(credits)X>X2:
XXXXXXXXXXXXXXXXdirectorX=Xcredits[0].a.text
XXXXXXXXXXXXXXXXwriterX=Xcredits[1].a.text
XXXXXXXXXXXXXXXXactorsX=X[]
XXXXXXXXXXXXXXXXforXxXinXcredits[2].findAll("a"):
XXXXXXXXXXXXXXXXXXXXactors.append(x.text)
XXXXXXXXXXXXXXXXactors.pop()
XXXXXXXXXXXXXXXXstarsX=Xactors[0]X+X","X+Xactors[1]X+X","X+Xactors[2]
XXXXXXXXXXXXelse:
XXXXXXXXXXXXXXXXdirectorX=Xcredits[0].a.text
XXXXXXXXXXXXXXXXwriterX=X"NotXavailable"
XXXXXXXXXXXXXXXXactorsX=X[]
XXXXXXXXXXXXXXXXforXxXinXcredits[1].findAll("a"):
XXXXXXXXXXXXXXXXXXXXactors.append(x.text)
XXXXXXXXXXXXXXXXactors.pop()
XXXXXXXXXXXXXXXXstarsX=Xactors[0]X+X","X+Xactors[1]X+X","X+Xactors[2]
XXXXXXXXXXXXifXsoup.find("div",X"inlineXcanwrap"):
XXXXXXXXXXXXXXXXstory_lineX=Xsoup.find("div",X"inlineXcanwrap").findAll("p")[0].text
XXXXXXXXXXXXelse:
XXXXXXXXXXXXXXXXstory_lineX=X"NotXavailable"
XXXXXXXXXXXXinfoX=Xsoup.findAll("div",X"txt-block")
XXXXXXXXXXXXifXinfo:
XXXXXXXXXXXXXXXXmov_countryX=X[]
XXXXXXXXXXXXXXXXmov_languageX=X[]
XXXXXXXXXXXXXXXXforXnodeXinXinfo:
XXXXXXXXXXXXXXXXXXXXaX=Xnode.findAll("a")
XXXXXXXXXXXXXXXXXXXXforXiXinXa:
XXXXXXXXXXXXXXXXXXXXXXXXifX"country_of_origin"XinXi["href"]:
XXXXXXXXXXXXXXXXXXXXXXXXXXXXmov_country.append(i.text)
XXXXXXXXXXXXXXXXXXXXXXXXelifX"primary_language"XinXi["href"]:
XXXXXXXXXXXXXXXXXXXXXXXXXXXXmov_language.append(i.text)
XXXXXXXXXXXXifXsoup.findAll("div",X"ratingValue"):
XXXXXXXXXXXXXXXXforXrXinXsoup.findAll("div",X"ratingValue"):
XXXXXXXXXXXXXXXXXXXXmov_ratingX=Xr.strong["title"]
XXXXXXXXXXXXelse:
XXXXXXXXXXXXXXXXmov_ratingX=X"NotXavailable"
XXXXXXXXXXXXlolX=Xf"MovieX-X{mov_title}\nXClickXtoXseeXmore"
XXXXXXXXXXXXmsgX=X(
XXXXXXXXXXXXXXXX"<aXhref="X+XposterX+X">&#8203;</a>"
XXXXXXXXXXXXXXXX"<b>TitleX:X</b><code>"
XXXXXXXXXXXXXXXX+Xmov_title
XXXXXXXXXXXXXXXX+X"</code>\n<code>"
XXXXXXXXXXXXXXXX+Xmov_details
XXXXXXXXXXXXXXXX+X"</code>\n<b>RatingX:X</b><code>"
XXXXXXXXXXXXXXXX+Xmov_rating
XXXXXXXXXXXXXXXX+X"</code>\n<b>CountryX:X</b><code>"
XXXXXXXXXXXXXXXX+Xmov_country[0]
XXXXXXXXXXXXXXXX+X"</code>\n<b>LanguageX:X</b><code>"
XXXXXXXXXXXXXXXX+Xmov_language[0]
XXXXXXXXXXXXXXXX+X"</code>\n<b>DirectorX:X</b><code>"
XXXXXXXXXXXXXXXX+Xdirector
XXXXXXXXXXXXXXXX+X"</code>\n<b>WriterX:X</b><code>"
XXXXXXXXXXXXXXXX+Xwriter
XXXXXXXXXXXXXXXX+X"</code>\n<b>StarsX:X</b><code>"
XXXXXXXXXXXXXXXX+Xstars
XXXXXXXXXXXXXXXX+X"</code>\n<b>IMDBXUrlX:X</b>"
XXXXXXXXXXXXXXXX+Xmov_link
XXXXXXXXXXXXXXXX+X"\n<b>StoryXLineX:X</b>"
XXXXXXXXXXXXXXXX+Xstory_line
XXXXXXXXXXXX)
XXXXXXXXXXXXresults.append(
XXXXXXXXXXXXXXXXInlineQueryResultArticle(
XXXXXXXXXXXXXXXXXXXXtitle="ImdbXSearch",
XXXXXXXXXXXXXXXXXXXXdescription=lol,
XXXXXXXXXXXXXXXXXXXXinput_message_content=InputTextMessageContent(
XXXXXXXXXXXXXXXXXXXXXXXXmsg,Xdisable_web_page_preview=False,Xparse_mode="HTML"
XXXXXXXXXXXXXXXXXXXX),
XXXXXXXXXXXXXXXX)
XXXXXXXXXXXX)
XXXXXXXXXXXXawaitXclient.answer_inline_query(query.id,Xcache_time=0,Xresults=results)
XXXXXXXXelifXtext.split()[0]X==X"spaminfo":
XXXXXXXXXXXXcmdX=Xtext.split(None,X1)[1]
XXXXXXXXXXXXresultsX=X[]
XXXXXXXXXXXXurlX=Xf"https://api.intellivoid.net/spamprotection/v1/lookup?query={cmd}"
XXXXXXXXXXXXaX=XawaitXAioHttp().get_json(url)
XXXXXXXXXXXXresponseX=Xa["success"]
XXXXXXXXXXXXifXresponseXisXTrue:
XXXXXXXXXXXXXXXXdateX=Xa["results"]["last_updated"]
XXXXXXXXXXXXXXXXstatsX=Xf"**◢XIntellivoid•XSpamProtectionXInfo**:\n"
XXXXXXXXXXXXXXXXstatsX+=Xf'X•X**UpdatedXon**:X`{datetime.fromtimestamp(date).strftime("%Y-%m-%dX%I:%M:%SX%p")}`\n'
XXXXXXXXXXXXXXXXstatsX+=Xf"X•X**ChatXInfo**:X[Link](t.me/SpamProtectionBot/?start=00_{cmd})\n"

XXXXXXXXXXXXXXXXifXa["results"]["attributes"]["is_potential_spammer"]XisXTrue:
XXXXXXXXXXXXXXXXXXXXstatsX+=Xf"X•X**User**:X`USERxSPAM`\n"
XXXXXXXXXXXXXXXXelifXa["results"]["attributes"]["is_operator"]XisXTrue:
XXXXXXXXXXXXXXXXXXXXstatsX+=Xf"X•X**User**:X`USERxOPERATOR`\n"
XXXXXXXXXXXXXXXXelifXa["results"]["attributes"]["is_agent"]XisXTrue:
XXXXXXXXXXXXXXXXXXXXstatsX+=Xf"X•X**User**:X`USERxAGENT`\n"
XXXXXXXXXXXXXXXXelifXa["results"]["attributes"]["is_whitelisted"]XisXTrue:
XXXXXXXXXXXXXXXXXXXXstatsX+=Xf"X•X**User**:X`USERxWHITELISTED`\n"

XXXXXXXXXXXXXXXXstatsX+=Xf'X•X**Type**:X`{a["results"]["entity_type"]}`\n'
XXXXXXXXXXXXXXXXstatsX+=Xf'X•X**Language**:X`{a["results"]["language_prediction"]["language"]}`\n'
XXXXXXXXXXXXXXXXstatsX+=Xf'X•X**LanguageXProbability**:X`{a["results"]["language_prediction"]["probability"]}`\n'
XXXXXXXXXXXXXXXXstatsX+=Xf"**SpamXPrediction**:\n"
XXXXXXXXXXXXXXXXstatsX+=Xf'X•X**HamXPrediction**:X`{a["results"]["spam_prediction"]["ham_prediction"]}`\n'
XXXXXXXXXXXXXXXXstatsX+=Xf'X•X**SpamXPrediction**:X`{a["results"]["spam_prediction"]["spam_prediction"]}`\n'
XXXXXXXXXXXXXXXXstatsX+=Xf'**Blacklisted**:X`{a["results"]["attributes"]["is_blacklisted"]}`\n'
XXXXXXXXXXXXXXXXifXa["results"]["attributes"]["is_blacklisted"]XisXTrue:
XXXXXXXXXXXXXXXXXXXXstatsX+=Xf'X•X**Reason**:X`{a["results"]["attributes"]["blacklist_reason"]}`\n'
XXXXXXXXXXXXXXXXXXXXstatsX+=Xf'X•X**Flag**:X`{a["results"]["attributes"]["blacklist_flag"]}`\n'
XXXXXXXXXXXXXXXXstatsX+=Xf'**PTID**:\n`{a["results"]["private_telegram_id"]}`\n'
XXXXXXXXXXXXXXXXresults.append(
XXXXXXXXXXXXXXXXXXXXInlineQueryResultArticle(
XXXXXXXXXXXXXXXXXXXXXXXXtitle="SpamXInfo",
XXXXXXXXXXXXXXXXXXXXXXXXdescription="SearchXUsersXspamXinfo",
XXXXXXXXXXXXXXXXXXXXXXXXinput_message_content=InputTextMessageContent(
XXXXXXXXXXXXXXXXXXXXXXXXXXXXstats,Xdisable_web_page_preview=True
XXXXXXXXXXXXXXXXXXXXXXXX),
XXXXXXXXXXXXXXXXXXXX)
XXXXXXXXXXXXXXXX)
XXXXXXXXXXXXXXXXawaitXclient.answer_inline_query(
XXXXXXXXXXXXXXXXXXXXquery.id,Xcache_time=0,Xresults=results
XXXXXXXXXXXXXXXX)
XXXXXXXXelifXtext.split()[0]X==X"lyrics":
XXXXXXXXXXXXcmdX=Xtext.split(None,X1)[1]
XXXXXXXXXXXXresultsX=X[]

XXXXXXXXXXXXsongX=X""
XXXXXXXXXXXXsongX=XSong.find_song(cmd)
XXXXXXXXXXXXifXsong:
XXXXXXXXXXXXXXXXifXsong.lyrics:
XXXXXXXXXXXXXXXXXXXXreplyX=Xsong.format()
XXXXXXXXXXXXXXXXelse:
XXXXXXXXXXXXXXXXXXXXreplyX=X"Couldn'tXfindXanyXlyricsXforXthatXsong!XtryXwithXartistXnameXalongXwithXsongXifXstillXdoesntXworkXtryX`.glyrics`"
XXXXXXXXXXXXelse:
XXXXXXXXXXXXXXXXreplyX=X"lyricsXnotXfound!XtryXwithXartistXnameXalongXwithXsongXifXstillXdoesntXworkXtryX`.glyrics`"

XXXXXXXXXXXXifXlen(reply)X>X4095:
XXXXXXXXXXXXXXXXreplyX=X"lyricsXtooXbig,XTryXusingX/lyrics"

XXXXXXXXXXXXresults.append(
XXXXXXXXXXXXXXXXInlineQueryResultArticle(
XXXXXXXXXXXXXXXXXXXXtitle="SongXLyrics",
XXXXXXXXXXXXXXXXXXXXdescription="ClickXhereXtoXseeXlyrics",
XXXXXXXXXXXXXXXXXXXXinput_message_content=InputTextMessageContent(
XXXXXXXXXXXXXXXXXXXXXXXXreply,Xdisable_web_page_preview=False
XXXXXXXXXXXXXXXXXXXX),
XXXXXXXXXXXXXXXX)
XXXXXXXXXXXX)
XXXXXXXXXXXXawaitXclient.answer_inline_query(query.id,Xcache_time=0,Xresults=results)
XXXXXXXXelifXtext.split()[0]X==X"pokedex":
XXXXXXXXXXXXifXlen(text.split())X<X2:
XXXXXXXXXXXXXXXXawaitXclient.answer_inline_query(
XXXXXXXXXXXXXXXXXXXXquery.id,
XXXXXXXXXXXXXXXXXXXXresults=answers,
XXXXXXXXXXXXXXXXXXXXswitch_pm_text="PokemonX[text]",
XXXXXXXXXXXXXXXXXXXXswitch_pm_parameter="pokedex",
XXXXXXXXXXXXXXXX)
XXXXXXXXXXXXXXXXreturn
XXXXXXXXXXXXpokedexX=Xtext.split(None,X1)[1].strip()
XXXXXXXXXXXXPokedexX=XawaitXpokedexinfo(answers,Xpokedex)
XXXXXXXXXXXXawaitXclient.answer_inline_query(query.id,Xresults=Pokedex,Xcache_time=2)
XXXXXXXXelifXtext.split()[0]X==X"paste":
XXXXXXXXXXXXtexX=Xtext.split(None,X1)[1]
XXXXXXXXXXXXanswerssX=XawaitXpaste_func(answers,Xtex)
XXXXXXXXXXXXawaitXclient.answer_inline_query(query.id,Xresults=answerss,Xcache_time=2)

XXXXXXXXelifXtext.split()[0]X==X"covid":
XXXXXXXXXXXXlelX=Xtext.split(None,X1)[1]
XXXXXXXXXXXXresultsX=X[]
XXXXXXXXXXXXcountryX=Xlel.replace("X",X"")
XXXXXXXXXXXXdataX=XawaitXfetch(f"https://corona.lmao.ninja/v2/countries/{country}")
XXXXXXXXXXXXdataX=XawaitXjson_prettify(data)
XXXXXXXXXXXXresults.append(
XXXXXXXXXXXXXXXXInlineQueryResultArticle(
XXXXXXXXXXXXXXXXXXXXtitle="CovidXInfoXGatheredXsuccesfully",
XXXXXXXXXXXXXXXXXXXXdescription=data,
XXXXXXXXXXXXXXXXXXXXinput_message_content=InputTextMessageContent(
XXXXXXXXXXXXXXXXXXXXXXXXdata,Xdisable_web_page_preview=False
XXXXXXXXXXXXXXXXXXXX),
XXXXXXXXXXXXXXXX)
XXXXXXXXXXXX)
XXXXXXXXXXXXawaitXclient.answer_inline_query(query.id,Xresults=results,Xcache_time=2)
XXXXXXXXelifXtext.split()[0]X==X"country":
XXXXXXXXXXXXlelX=Xtext.split(None,X1)[1]
XXXXXXXXXXXXresultsX=X[]
XXXXXXXXXXXXcountryX=XCountryInfo(lel)
XXXXXXXXXXXXtry:
XXXXXXXXXXXXXXXXaX=Xcountry.info()
XXXXXXXXXXXXexcept:
XXXXXXXXXXXXXXXXaX=X"CountryXNotXAvaiableXCurrently"
XXXXXXXXXXXXnameX=Xa.get("name")
XXXXXXXXXXXXbbX=Xa.get("altSpellings")
XXXXXXXXXXXXhuX=X""
XXXXXXXXXXXXforXpXinXbb:
XXXXXXXXXXXXXXXXhuX+=XpX+X",XX"

XXXXXXXXXXXXareaX=Xa.get("area")
XXXXXXXXXXXXbordersX=X""
XXXXXXXXXXXXhellX=Xa.get("borders")
XXXXXXXXXXXXforXfkXinXhell:
XXXXXXXXXXXXXXXXbordersX+=XfkX+X",XX"

XXXXXXXXXXXXcallX=X""
XXXXXXXXXXXXWhAtX=Xa.get("callingCodes")
XXXXXXXXXXXXforXwhatXinXWhAt:
XXXXXXXXXXXXXXXXcallX+=XwhatX+X"XX"

XXXXXXXXXXXXcapitalX=Xa.get("capital")
XXXXXXXXXXXXcurrenciesX=X""
XXXXXXXXXXXXfkerX=Xa.get("currencies")
XXXXXXXXXXXXforXFKerXinXfker:
XXXXXXXXXXXXXXXXcurrenciesX+=XFKerX+X",XX"

XXXXXXXXXXXXHmMX=Xa.get("demonym")
XXXXXXXXXXXXgeoX=Xa.get("geoJSON")
XXXXXXXXXXXXpabloX=Xgeo.get("features")
XXXXXXXXXXXXPabloX=Xpablo[0]
XXXXXXXXXXXXPAbloX=XPablo.get("geometry")
XXXXXXXXXXXXEsCoBaRX=XPAblo.get("type")
XXXXXXXXXXXXisoX=X""
XXXXXXXXXXXXiSoX=Xa.get("ISO")
XXXXXXXXXXXXforXhitlerXinXiSo:
XXXXXXXXXXXXXXXXpoX=XiSo.get(hitler)
XXXXXXXXXXXXXXXXisoX+=XpoX+X",XX"
XXXXXXXXXXXXflaX=XiSo.get("alpha2")
XXXXXXXXXXXXfla.upper()

XXXXXXXXXXXXlanguagesX=Xa.get("languages")
XXXXXXXXXXXXlMAOX=X""
XXXXXXXXXXXXforXlmaoXinXlanguages:
XXXXXXXXXXXXXXXXlMAOX+=XlmaoX+X",XX"

XXXXXXXXXXXXnoniveX=Xa.get("nativeName")
XXXXXXXXXXXXwasteX=Xa.get("population")
XXXXXXXXXXXXregX=Xa.get("region")
XXXXXXXXXXXXsubX=Xa.get("subregion")
XXXXXXXXXXXXtikX=Xa.get("timezones")
XXXXXXXXXXXXtomX=X""
XXXXXXXXXXXXforXjerryXinXtik:
XXXXXXXXXXXXXXXXtomX+=XjerryX+X",XXX"

XXXXXXXXXXXXGOTX=Xa.get("tld")
XXXXXXXXXXXXlanesterX=X""
XXXXXXXXXXXXforXtargaryenXinXGOT:
XXXXXXXXXXXXXXXXlanesterX+=XtargaryenX+X",XXX"

XXXXXXXXXXXXwikiX=Xa.get("wiki")

XXXXXXXXXXXXcaptionX=Xf"""<b><u>InformationXGatheredXSuccessfully</b></u>
XXXXXXXX<b>
XXXXXXXXCountryXName:-X{name}
XXXXXXXXAlternativeXSpellings:-X{hu}
XXXXXXXXCountryXArea:-X{area}XsquareXkilometers
XXXXXXXXBorders:-X{borders}
XXXXXXXXCallingXCodes:-X{call}
XXXXXXXXCountry'sXCapital:-X{capital}
XXXXXXXXCountry'sXcurrency:-X{currencies}
XXXXXXXXDemonym:-X{HmM}
XXXXXXXXCountryXType:-X{EsCoBaR}
XXXXXXXXISOXNames:-X{iso}
XXXXXXXXLanguages:-X{lMAO}
XXXXXXXXNativeXName:-X{nonive}
XXXXXXXXpopulation:-X{waste}
XXXXXXXXRegion:-X{reg}
XXXXXXXXSubXRegion:-X{sub}
XXXXXXXXTimeXZones:-X{tom}
XXXXXXXXTopXLevelXDomain:-X{lanester}
XXXXXXXXwikipedia:-X{wiki}</b>
XXXXXXXXGatheredXByXInerukiXX.</b>
XXXXXXXX"""
XXXXXXXXXXXXresults.append(
XXXXXXXXXXXXXXXXInlineQueryResultArticle(
XXXXXXXXXXXXXXXXXXXXtitle=f"InfomationXofX{name}",
XXXXXXXXXXXXXXXXXXXXdescription=f"""
XXXXXXXXCountryXName:-X{name}
XXXXXXXXAlternativeXSpellings:-X{hu}
XXXXXXXXCountryXArea:-X{area}XsquareXkilometers
XXXXXXXXBorders:-X{borders}
XXXXXXXXCallingXCodes:-X{call}
XXXXXXXXCountry'sXCapital:-X{capital}
XXXXXXXX
XXXXXXXXTouchXforXmoreXinfo
XXXXXXXX""",
XXXXXXXXXXXXXXXXXXXXinput_message_content=InputTextMessageContent(
XXXXXXXXXXXXXXXXXXXXXXXXcaption,Xparse_mode="HTML",Xdisable_web_page_preview=True
XXXXXXXXXXXXXXXXXXXX),
XXXXXXXXXXXXXXXX)
XXXXXXXXXXXX)
XXXXXXXXXXXXawaitXclient.answer_inline_query(query.id,Xresults=results,Xcache_time=2)

XXXXXXXXelifXtext.split()[0]X==X"fakegen":
XXXXXXXXXXXXresultsX=X[]
XXXXXXXXXXXXfakeX=XFaker()
XXXXXXXXXXXXnameX=Xstr(fake.name())
XXXXXXXXXXXXfake.add_provider(internet)
XXXXXXXXXXXXaddressX=Xstr(fake.address())
XXXXXXXXXXXXipX=Xfake.ipv4_private()
XXXXXXXXXXXXccX=Xfake.credit_card_full()
XXXXXXXXXXXXemailX=Xfake.ascii_free_email()
XXXXXXXXXXXXjobX=Xfake.job()
XXXXXXXXXXXXandroidX=Xfake.android_platform_token()
XXXXXXXXXXXXpcX=Xfake.chrome()
XXXXXXXXXXXXresX=Xf"<b><u>XFakeXInformationXGenerated</b></u>\n<b>NameX:-</b><code>{name}</code>\n\n<b>Address:-</b><code>{address}</code>\n\n<b>IPXADDRESS:-</b><code>{ip}</code>\n\n<b>creditXcard:-</b><code>{cc}</code>\n\n<b>EmailXId:-</b><code>{email}</code>\n\n<b>Job:-</b><code>{job}</code>\n\n<b>androidXuserXagent:-</b><code>{android}</code>\n\n<b>PcXuserXagent:-</b><code>{pc}</code>"
XXXXXXXXXXXXresults.append(
XXXXXXXXXXXXXXXXInlineQueryResultArticle(
XXXXXXXXXXXXXXXXXXXXtitle="FakeXinfomationXgathered",
XXXXXXXXXXXXXXXXXXXXdescription="ClickXhereXtoXseeXthem",
XXXXXXXXXXXXXXXXXXXXinput_message_content=InputTextMessageContent(
XXXXXXXXXXXXXXXXXXXXXXXXres,Xparse_mode="HTML",Xdisable_web_page_preview=True
XXXXXXXXXXXXXXXXXXXX),
XXXXXXXXXXXXXXXX)
XXXXXXXXXXXX)
XXXXXXXXXXXXawaitXclient.answer_inline_query(query.id,Xcache_time=0,Xresults=results)

XXXXXXXXelifXtext.split()[0]X==X"cs":
XXXXXXXXXXXXresultsX=X[]
XXXXXXXXXXXXscore_pageX=X"http://static.cricinfo.com/rss/livescores.xml"
XXXXXXXXXXXXpageX=Xurllib.request.urlopen(score_page)
XXXXXXXXXXXXsoupX=XBeautifulSoup(page,X"html.parser")
XXXXXXXXXXXXresultX=Xsoup.find_all("description")
XXXXXXXXXXXXSedX=X""
XXXXXXXXXXXXforXmatchXinXresult:
XXXXXXXXXXXXXXXXSedX+=Xmatch.get_text()X+X"\n\n"
XXXXXXXXXXXXresX=Xf"<b><u>MatchXinformationXgatheredXsuccessful</b></u>\n\n\n<code>{Sed}</code>"
XXXXXXXXXXXXresults.append(
XXXXXXXXXXXXXXXXInlineQueryResultArticle(
XXXXXXXXXXXXXXXXXXXXtitle="MatchXinformationXgathered",
XXXXXXXXXXXXXXXXXXXXdescription="ClickXhereXtoXseeXthem",
XXXXXXXXXXXXXXXXXXXXinput_message_content=InputTextMessageContent(
XXXXXXXXXXXXXXXXXXXXXXXXres,Xparse_mode="HTML",Xdisable_web_page_preview=False
XXXXXXXXXXXXXXXXXXXX),
XXXXXXXXXXXXXXXX)
XXXXXXXXXXXX)
XXXXXXXXXXXXawaitXclient.answer_inline_query(query.id,Xcache_time=0,Xresults=results)

XXXXXXXXelifXtext.split()[0]X==X"antonyms":
XXXXXXXXXXXXresultsX=X[]
XXXXXXXXXXXXlelX=Xtext.split(None,X1)[1]
XXXXXXXXXXXXwordX=Xf"{lel}"
XXXXXXXXXXXXletX=Xdictionary.antonym(word)
XXXXXXXXXXXXsetX=Xstr(let)
XXXXXXXXXXXXjetX=Xset.replace("{",X"")
XXXXXXXXXXXXnetX=Xjet.replace("}",X"")
XXXXXXXXXXXXgotX=Xnet.replace("'",X"")
XXXXXXXXXXXXresults.append(
XXXXXXXXXXXXXXXXInlineQueryResultArticle(
XXXXXXXXXXXXXXXXXXXXtitle=f"antonymsXforX{lel}",
XXXXXXXXXXXXXXXXXXXXdescription=got,
XXXXXXXXXXXXXXXXXXXXinput_message_content=InputTextMessageContent(
XXXXXXXXXXXXXXXXXXXXXXXXgot,Xdisable_web_page_preview=False
XXXXXXXXXXXXXXXXXXXX),
XXXXXXXXXXXXXXXX)
XXXXXXXXXXXX)
XXXXXXXXXXXXawaitXclient.answer_inline_query(query.id,Xcache_time=0,Xresults=results)

XXXXXXXXelifXtext.split()[0]X==X"synonyms":
XXXXXXXXXXXXresultsX=X[]
XXXXXXXXXXXXlelX=Xtext.split(None,X1)[1]
XXXXXXXXXXXXwordX=Xf"{lel}"
XXXXXXXXXXXXletX=Xdictionary.synonym(word)
XXXXXXXXXXXXsetX=Xstr(let)
XXXXXXXXXXXXjetX=Xset.replace("{",X"")
XXXXXXXXXXXXnetX=Xjet.replace("}",X"")
XXXXXXXXXXXXgotX=Xnet.replace("'",X"")
XXXXXXXXXXXXresults.append(
XXXXXXXXXXXXXXXXInlineQueryResultArticle(
XXXXXXXXXXXXXXXXXXXXtitle=f"antonymsXforX{lel}",
XXXXXXXXXXXXXXXXXXXXdescription=got,
XXXXXXXXXXXXXXXXXXXXinput_message_content=InputTextMessageContent(
XXXXXXXXXXXXXXXXXXXXXXXXgot,Xdisable_web_page_preview=False
XXXXXXXXXXXXXXXXXXXX),
XXXXXXXXXXXXXXXX)
XXXXXXXXXXXX)
XXXXXXXXXXXXawaitXclient.answer_inline_query(query.id,Xcache_time=0,Xresults=results)

XXXXXXXXelifXtext.split()[0]X==X"define":
XXXXXXXXXXXXresultsX=X[]
XXXXXXXXXXXXlelX=Xtext.split(None,X1)[1]
XXXXXXXXXXXXwordX=Xf"{lel}"
XXXXXXXXXXXXletX=Xdictionary.meaning(word)
XXXXXXXXXXXXsetX=Xstr(let)
XXXXXXXXXXXXjetX=Xset.replace("{",X"")
XXXXXXXXXXXXnetX=Xjet.replace("}",X"")
XXXXXXXXXXXXgotX=Xnet.replace("'",X"")
XXXXXXXXXXXXresults.append(
XXXXXXXXXXXXXXXXInlineQueryResultArticle(
XXXXXXXXXXXXXXXXXXXXtitle=f"DefinitionXforX{lel}",
XXXXXXXXXXXXXXXXXXXXdescription=got,
XXXXXXXXXXXXXXXXXXXXinput_message_content=InputTextMessageContent(
XXXXXXXXXXXXXXXXXXXXXXXXgot,Xdisable_web_page_preview=False
XXXXXXXXXXXXXXXXXXXX),
XXXXXXXXXXXXXXXX)
XXXXXXXXXXXX)
XXXXXXXXXXXXawaitXclient.answer_inline_query(query.id,Xcache_time=0,Xresults=results)

XXXXXXXXelifXtext.split()[0]X==X"weather":
XXXXXXXXXXXXresultsX=X[]
XXXXXXXXXXXXsample_urlX=X"https://api.openweathermap.org/data/2.5/weather?q={}&APPID={}&units=metric"
XXXXXXXXXXXXinput_strX=Xtext.split(None,X1)[1]
XXXXXXXXXXXXasyncXwithXaiohttp.ClientSession()XasXsession:
XXXXXXXXXXXXXXXXresponse_api_zeroX=XawaitXsession.get(
XXXXXXXXXXXXXXXXXXXXsample_url.format(input_str,XOPENWEATHERMAP_ID)
XXXXXXXXXXXXXXXX)
XXXXXXXXXXXXresponse_apiX=XawaitXresponse_api_zero.json()
XXXXXXXXXXXXifXresponse_api["cod"]X==X200:
XXXXXXXXXXXXXXXXcountry_codeX=Xresponse_api["sys"]["country"]
XXXXXXXXXXXXXXXXcountry_time_zoneX=Xint(response_api["timezone"])
XXXXXXXXXXXXXXXXsun_rise_timeX=Xint(response_api["sys"]["sunrise"])X+Xcountry_time_zone
XXXXXXXXXXXXXXXXsun_set_timeX=Xint(response_api["sys"]["sunset"])X+Xcountry_time_zone
XXXXXXXXXXXXXXXXlolX=X"""X
XXXXXXXXWEATHERXINFOXGATHERED
XXXXXXXXLocation:X{}
XXXXXXXXTemperatureX☀️:X{}°С
XXXXXXXXXXXXminimium:X{}°С
XXXXXXXXXXXXmaximumX:X{}°С
XXXXXXXXHumidityX🌤**:X{}%
XXXXXXXXWindX💨:X{}m/s
XXXXXXXXCloudsX☁️:X{}hpa
XXXXXXXXSunriseX🌤:X{}X{}
XXXXXXXXSunsetX🌝:X{}X{}""".format(
XXXXXXXXXXXXXXXXXXXXinput_str,
XXXXXXXXXXXXXXXXXXXXresponse_api["main"]["temp"],
XXXXXXXXXXXXXXXXXXXXresponse_api["main"]["temp_min"],
XXXXXXXXXXXXXXXXXXXXresponse_api["main"]["temp_max"],
XXXXXXXXXXXXXXXXXXXXresponse_api["main"]["humidity"],
XXXXXXXXXXXXXXXXXXXXresponse_api["wind"]["speed"],
XXXXXXXXXXXXXXXXXXXXresponse_api["clouds"]["all"],
XXXXXXXXXXXXXXXXXXXX#Xresponse_api["main"]["pressure"],
XXXXXXXXXXXXXXXXXXXXtime.strftime("%Y-%m-%dX%H:%M:%S",Xtime.gmtime(sun_rise_time)),
XXXXXXXXXXXXXXXXXXXXcountry_code,
XXXXXXXXXXXXXXXXXXXXtime.strftime("%Y-%m-%dX%H:%M:%S",Xtime.gmtime(sun_set_time)),
XXXXXXXXXXXXXXXXXXXXcountry_code,
XXXXXXXXXXXXXXXX)
XXXXXXXXXXXXXXXXresults.append(
XXXXXXXXXXXXXXXXXXXXInlineQueryResultArticle(
XXXXXXXXXXXXXXXXXXXXXXXXtitle=f"WeatherXInformation",
XXXXXXXXXXXXXXXXXXXXXXXXdescription=lol,
XXXXXXXXXXXXXXXXXXXXXXXXinput_message_content=InputTextMessageContent(
XXXXXXXXXXXXXXXXXXXXXXXXXXXXlol,Xdisable_web_page_preview=True
XXXXXXXXXXXXXXXXXXXXXXXX),
XXXXXXXXXXXXXXXXXXXX)
XXXXXXXXXXXXXXXX)
XXXXXXXXXXXXXXXXawaitXclient.answer_inline_query(
XXXXXXXXXXXXXXXXXXXXquery.id,Xcache_time=0,Xresults=results
XXXXXXXXXXXXXXXX)

XXXXXXXXelifXtext.split()[0]X==X"datetime":
XXXXXXXXXXXXresultsX=X[]
XXXXXXXXXXXXgayX=Xtext.split(None,X1)[1]
XXXXXXXXXXXXlelX=Xgay
XXXXXXXXXXXXquery_timezoneX=Xlel.lower()
XXXXXXXXXXXXifXlen(query_timezone)X==X2:
XXXXXXXXXXXXXXXXresultX=Xgenerate_time(query_timezone,X["countryCode"])
XXXXXXXXXXXXelse:
XXXXXXXXXXXXXXXXresultX=Xgenerate_time(query_timezone,X["zoneName",X"countryName"])

XXXXXXXXXXXXifXnotXresult:
XXXXXXXXXXXXXXXXresultX=Xf"TimezoneXinfoXnotXavailableXforX<b>{lel}</b>"

XXXXXXXXXXXXresults.append(
XXXXXXXXXXXXXXXXInlineQueryResultArticle(
XXXXXXXXXXXXXXXXXXXXtitle=f"DateX&XTimeXinfoXofX{lel}",
XXXXXXXXXXXXXXXXXXXXdescription=result,
XXXXXXXXXXXXXXXXXXXXinput_message_content=InputTextMessageContent(
XXXXXXXXXXXXXXXXXXXXXXXXresult,Xdisable_web_page_preview=False,Xparse_mode="html"
XXXXXXXXXXXXXXXXXXXX),
XXXXXXXXXXXXXXXX)
XXXXXXXXXXXX)
XXXXXXXXXXXXawaitXclient.answer_inline_query(query.id,Xcache_time=0,Xresults=results)

XXXXXXXXelifXtext.split()[0]X==X"app":
XXXXXXXXXXXXripX=X[]
XXXXXXXXXXXXapp_nameX=Xtext.split(None,X1)[1]
XXXXXXXXXXXXremove_spaceX=Xapp_name.split("X")
XXXXXXXXXXXXfinal_nameX=X"+".join(remove_space)
XXXXXXXXXXXXpageX=Xrequests.get(
XXXXXXXXXXXXXXXX"https://play.google.com/store/search?q="X+Xfinal_nameX+X"&c=apps"
XXXXXXXXXXXX)
XXXXXXXXXXXXstr(page.status_code)
XXXXXXXXXXXXsoupX=XBeautifulSoup(page.content,X"lxml",Xfrom_encoding="utf-8")
XXXXXXXXXXXXresultsX=Xsoup.findAll("div",X"ZmHEEd")
XXXXXXXXXXXXapp_nameX=X(
XXXXXXXXXXXXXXXXresults[0]
XXXXXXXXXXXXXXXX.findNext("div",X"Vpfmgd")
XXXXXXXXXXXXXXXX.findNext("div",X"WsMG1cXnnK0zc")
XXXXXXXXXXXXXXXX.text
XXXXXXXXXXXX)
XXXXXXXXXXXXapp_devX=X(
XXXXXXXXXXXXXXXXresults[0].findNext("div",X"Vpfmgd").findNext("div",X"KoLSrc").text
XXXXXXXXXXXX)
XXXXXXXXXXXXapp_dev_linkX=X(
XXXXXXXXXXXXXXXX"https://play.google.com"
XXXXXXXXXXXXXXXX+Xresults[0].findNext("div",X"Vpfmgd").findNext("a",X"mnKHRc")["href"]
XXXXXXXXXXXX)
XXXXXXXXXXXXapp_ratingX=X(
XXXXXXXXXXXXXXXXresults[0]
XXXXXXXXXXXXXXXX.findNext("div",X"Vpfmgd")
XXXXXXXXXXXXXXXX.findNext("div",X"pf5lIe")
XXXXXXXXXXXXXXXX.find("div")["aria-label"]
XXXXXXXXXXXX)
XXXXXXXXXXXXapp_linkX=X(
XXXXXXXXXXXXXXXX"https://play.google.com"
XXXXXXXXXXXXXXXX+Xresults[0]
XXXXXXXXXXXXXXXX.findNext("div",X"Vpfmgd")
XXXXXXXXXXXXXXXX.findNext("div",X"vU6FJXp63iDd")
XXXXXXXXXXXXXXXX.a["href"]
XXXXXXXXXXXX)
XXXXXXXXXXXXapp_iconX=X(
XXXXXXXXXXXXXXXXresults[0]
XXXXXXXXXXXXXXXX.findNext("div",X"Vpfmgd")
XXXXXXXXXXXXXXXX.findNext("div",X"uzcko")
XXXXXXXXXXXXXXXX.img["data-src"]
XXXXXXXXXXXX)
XXXXXXXXXXXXapp_detailsX=X"<aXhref='"X+Xapp_iconX+X"'>📲&#8203;</a>"
XXXXXXXXXXXXapp_detailsX+=X"X<b>"X+Xapp_nameX+X"</b>"
XXXXXXXXXXXXapp_detailsX+=X(
XXXXXXXXXXXXXXXX"\n\n<code>DeveloperX:</code>X<aXhref='"
XXXXXXXXXXXXXXXX+Xapp_dev_link
XXXXXXXXXXXXXXXX+X"'>"
XXXXXXXXXXXXXXXX+Xapp_dev
XXXXXXXXXXXXXXXX+X"</a>"
XXXXXXXXXXXX)
XXXXXXXXXXXXapp_detailsX+=X"\n<code>RatingX:</code>X"X+Xapp_rating.replace(
XXXXXXXXXXXXXXXX"RatedX",X"⭐X"
XXXXXXXXXXXX).replace("XoutXofX",X"/").replace("Xstars",X"",X1).replace(
XXXXXXXXXXXXXXXX"Xstars",X"⭐X"
XXXXXXXXXXXX).replace(
XXXXXXXXXXXXXXXX"five",X"5"
XXXXXXXXXXXX)
XXXXXXXXXXXXapp_detailsX+=X(
XXXXXXXXXXXXXXXX"\n<code>FeaturesX:</code>X<aXhref='"
XXXXXXXXXXXXXXXX+Xapp_link
XXXXXXXXXXXXXXXX+X"'>ViewXinXPlayXStore</a>"
XXXXXXXXXXXX)
XXXXXXXXXXXXapp_detailsX+=X"\n\n===>X@InerukiSupport_OfficialX<==="
XXXXXXXXXXXXrip.append(
XXXXXXXXXXXXXXXXInlineQueryResultArticle(
XXXXXXXXXXXXXXXXXXXXtitle=f"DatailsXofX{app_name}",
XXXXXXXXXXXXXXXXXXXXdescription=app_details,
XXXXXXXXXXXXXXXXXXXXinput_message_content=InputTextMessageContent(
XXXXXXXXXXXXXXXXXXXXXXXXapp_details,Xdisable_web_page_preview=True,Xparse_mode="html"
XXXXXXXXXXXXXXXXXXXX),
XXXXXXXXXXXXXXXX)
XXXXXXXXXXXX)
XXXXXXXXXXXXawaitXclient.answer_inline_query(query.id,Xcache_time=0,Xresults=rip)

XXXXXXXXelifXtext.split()[0]X==X"gh":
XXXXXXXXXXXXresultsX=X[]
XXXXXXXXXXXXgettX=Xtext.split(None,X1)[1]
XXXXXXXXXXXXtextX=XgettX+X'X"site:github.com"'
XXXXXXXXXXXXgresultsX=XawaitXGoogleSearch().async_search(text,X1)
XXXXXXXXXXXXresultX=X""
XXXXXXXXXXXXforXiXinXrange(4):
XXXXXXXXXXXXXXXXtry:
XXXXXXXXXXXXXXXXXXXXtitleX=Xgresults["titles"][i].replace("\n",X"X")
XXXXXXXXXXXXXXXXXXXXsourceX=Xgresults["links"][i]
XXXXXXXXXXXXXXXXXXXXdescriptionX=Xgresults["descriptions"][i]
XXXXXXXXXXXXXXXXXXXXresultX+=Xf"[{title}]({source})\n"
XXXXXXXXXXXXXXXXXXXXresultX+=Xf"`{description}`\n\n"
XXXXXXXXXXXXXXXXexceptXIndexError:
XXXXXXXXXXXXXXXXXXXXpass
XXXXXXXXXXXXresults.append(
XXXXXXXXXXXXXXXXInlineQueryResultArticle(
XXXXXXXXXXXXXXXXXXXXtitle=f"ResultsXforX{gett}",
XXXXXXXXXXXXXXXXXXXXdescription=f"XGithubXinfoXofX{title}\nXXTouchXtoXread",
XXXXXXXXXXXXXXXXXXXXinput_message_content=InputTextMessageContent(
XXXXXXXXXXXXXXXXXXXXXXXXresult,Xdisable_web_page_preview=True
XXXXXXXXXXXXXXXXXXXX),
XXXXXXXXXXXXXXXX)
XXXXXXXXXXXX)
XXXXXXXXXXXXawaitXclient.answer_inline_query(query.id,Xcache_time=0,Xresults=results)

XXXXXXXXelifXtext.split()[0]X==X"so":
XXXXXXXXXXXXresultsX=X[]
XXXXXXXXXXXXgettX=Xtext.split(None,X1)[1]
XXXXXXXXXXXXtextX=XgettX+X'X"site:stackoverflow.com"'
XXXXXXXXXXXXgresultsX=XawaitXGoogleSearch().async_search(text,X1)
XXXXXXXXXXXXresultX=X""
XXXXXXXXXXXXforXiXinXrange(4):
XXXXXXXXXXXXXXXXtry:
XXXXXXXXXXXXXXXXXXXXtitleX=Xgresults["titles"][i].replace("\n",X"X")
XXXXXXXXXXXXXXXXXXXXsourceX=Xgresults["links"][i]
XXXXXXXXXXXXXXXXXXXXdescriptionX=Xgresults["descriptions"][i]
XXXXXXXXXXXXXXXXXXXXresultX+=Xf"[{title}]({source})\n"
XXXXXXXXXXXXXXXXXXXXresultX+=Xf"`{description}`\n\n"
XXXXXXXXXXXXXXXXexceptXIndexError:
XXXXXXXXXXXXXXXXXXXXpass
XXXXXXXXXXXXresults.append(
XXXXXXXXXXXXXXXXInlineQueryResultArticle(
XXXXXXXXXXXXXXXXXXXXtitle=f"StackXoverflowXsaerchX-X{title}",
XXXXXXXXXXXXXXXXXXXXdescription=f"XTouchXtoXviewXsearchXresultsXonX{title}",
XXXXXXXXXXXXXXXXXXXXinput_message_content=InputTextMessageContent(
XXXXXXXXXXXXXXXXXXXXXXXXresult,Xdisable_web_page_preview=True
XXXXXXXXXXXXXXXXXXXX),
XXXXXXXXXXXXXXXX)
XXXXXXXXXXXX)
XXXXXXXXXXXXawaitXclient.answer_inline_query(query.id,Xcache_time=0,Xresults=results)

XXXXexceptX(IndexError,XTypeError,XKeyError,XValueError):
XXXXXXXXreturn


defXgenerate_time(to_find:Xstr,Xfindtype:XList[str])X->Xstr:
XXXXdataX=Xrequests.get(
XXXXXXXXf"http://api.timezonedb.com/v2.1/list-time-zone"
XXXXXXXXf"?key={TIME_API_KEY}"
XXXXXXXXf"&format=json"
XXXXXXXXf"&fields=countryCode,countryName,zoneName,gmtOffset,timestamp,dst"
XXXX).json()

XXXXforXzoneXinXdata["zones"]:
XXXXXXXXforXeachtypeXinXfindtype:
XXXXXXXXXXXXifXto_findXinXzone[eachtype].lower():
XXXXXXXXXXXXXXXXcountry_nameX=Xzone["countryName"]
XXXXXXXXXXXXXXXXcountry_zoneX=Xzone["zoneName"]
XXXXXXXXXXXXXXXXcountry_codeX=Xzone["countryCode"]

XXXXXXXXXXXXXXXXifXzone["dst"]X==X1:
XXXXXXXXXXXXXXXXXXXXdaylight_savingX=X"Yes"
XXXXXXXXXXXXXXXXelse:
XXXXXXXXXXXXXXXXXXXXdaylight_savingX=X"No"

XXXXXXXXXXXXXXXXdate_fmtX=Xr"%d-%m-%Y"
XXXXXXXXXXXXXXXXtime_fmtX=Xr"%H:%M:%S"
XXXXXXXXXXXXXXXXday_fmtX=Xr"%A"
XXXXXXXXXXXXXXXXgmt_offsetX=Xzone["gmtOffset"]
XXXXXXXXXXXXXXXXtimestampX=Xdatetime.datetime.now(
XXXXXXXXXXXXXXXXXXXXdatetime.timezone.utc
XXXXXXXXXXXXXXXX)X+Xdatetime.timedelta(seconds=gmt_offset)
XXXXXXXXXXXXXXXXcurrent_dateX=Xtimestamp.strftime(date_fmt)
XXXXXXXXXXXXXXXXcurrent_timeX=Xtimestamp.strftime(time_fmt)
XXXXXXXXXXXXXXXXcurrent_dayX=Xtimestamp.strftime(day_fmt)

XXXXXXXXXXXXXXXXbreak

XXXXtry:
XXXXXXXXresultX=X(
XXXXXXXXXXXXf"XDATEXANDXTIMEXOFXCOUNTRY"
XXXXXXXXXXXXf"🌍CountryX:{country_name}\n"
XXXXXXXXXXXXf"⏳ZoneXNameX:X{country_zone}\n"
XXXXXXXXXXXXf"🗺CountryXCode:X{country_code}\n"
XXXXXXXXXXXXf"🌞DaylightXsavingX:X{daylight_saving}\n"
XXXXXXXXXXXXf"🌅DayX:X{current_day}\n"
XXXXXXXXXXXXf"⌚CurrentXTimeX:X{current_time}\n"
XXXXXXXXXXXXf"📆CurrentXDateX:{current_date}"
XXXXXXXX)
XXXXexceptXBaseException:
XXXXXXXXresultX=XNone

XXXXreturnXresult
